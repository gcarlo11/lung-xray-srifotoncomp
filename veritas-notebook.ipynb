{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":108900,"databundleVersionId":13797659,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom torchvision import datasets, transforms, models\nimport timm \nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CONFIG\nDATA_DIR = \"/kaggle/input/srifoton\"\nTRAIN_DIR = os.path.join(DATA_DIR, \"train\", \"train\")\nVAL_DIR = os.path.join(DATA_DIR, \"val\", \"val\")\nTEST_DIR  = os.path.join(DATA_DIR, \"test\", \"test\")\nOUT_FILE  = \"/kaggle/working/submission.csv\"\nMODEL_DIR = \"/kaggle/working/models/\" \nos.makedirs(MODEL_DIR, exist_ok=True)\n\n# Hyperparameters \nBATCH_SIZE = 16 \nEPOCHS_PER_FOLD = 25 \nIMG_SIZE = 384 \nBACKBONE = \"efficientnet_v2_m\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLR = 1e-4\nN_FOLDS = 5\n\nprint(f\"Menggunakan device: {DEVICE}\")\nprint(f\"Model backbone: {BACKBONE}\")\nprint(f\"Ukuran gambar: {IMG_SIZE}x{IMG_SIZE}\")\nprint(f\"Strategi Pelatihan: {N_FOLDS}-Fold Cross-Validation\")\n\nprint(f\"Menggunakan device: {DEVICE}\")\nprint(f\"Model backbone: {BACKBONE}\")\nprint(f\"Ukuran gambar: {IMG_SIZE}x{IMG_SIZE}\")\nprint(f\"Strategi Pelatihan: {N_FOLDS}-Fold Cross-Validation\")\n\n# AUGMENTASI\ntrain_tfms = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), shear=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_test_tfms = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# SETUP DATASET UNTUK K-FOLD\ntrain_val_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tfms)\nfull_dataset_for_split = datasets.ImageFolder(TRAIN_DIR) \n\nclass_names = train_val_ds.classes\nn_classes = len(class_names)\nprint(f\"Jumlah kelas: {n_classes}, Nama kelas: {class_names}\")\n\nimage_paths = [item[0] for item in full_dataset_for_split.samples]\nlabels = [item[1] for item in full_dataset_for_split.samples]\n\ntest_imgs = sorted(glob(os.path.join(TEST_DIR, \"*\")))\n\nclass KFoldDatasetWrapper(Dataset):\n    def __init__(self, all_paths, all_labels, indices, transform):\n        self.paths = [all_paths[i] for i in indices]\n        self.labels = [all_labels[i] for i in indices]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img_path = self.paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# MODEL \ndef get_model(backbone_name, n_classes, pretrained=True):\n    weights = 'DEFAULT' if pretrained else None\n    if backbone_name == \"xception\":\n        model = timm.create_model('xception', pretrained=pretrained, num_classes=n_classes)\n        print(\"Model Xception dari 'timm' berhasil dimuat.\")\n    elif backbone_name == \"efficientnet_v2_m\":\n        model = models.efficientnet_v2_m(weights=weights)\n        in_features = model.classifier[1].in_features\n        model.classifier[1] = nn.Linear(in_features, n_classes)\n        print(\"Model EfficientNetV2-M berhasil dimuat.\")\n    else:\n        raise ValueError(\"Backbone tidak didukung\")\n    return model\n\n# LOOP PELATIHAN DENGAN STRATIFIED K-FOLD\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\nfold_histories = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n    print(f\"\\n===== FOLD {fold+1}/{N_FOLDS} =====\")\n\n    train_dataset = KFoldDatasetWrapper(image_paths, labels, train_idx, transform=train_tfms)\n    val_dataset = KFoldDatasetWrapper(image_paths, labels, val_idx, transform=val_test_tfms)\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=2, pin_memory=True)\n\n    model = get_model(BACKBONE, n_classes).to(DEVICE)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-2)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-6)\n    \n    best_val_acc = 0.0\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_f1': []}\n\n    for epoch in range(EPOCHS_PER_FOLD):\n        print(f\"\\n--- Epoch {epoch+1}/{EPOCHS_PER_FOLD} ---\")\n        \n        # Training\n        model.train()\n        train_loss, train_correct, train_total = 0, 0, 0\n        pbar_train = tqdm(train_loader, desc=f\"Training Fold {fold+1}\")\n        for imgs, lbls in pbar_train:\n            imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n            \n            optimizer.zero_grad()\n            outputs = model(imgs)\n            loss = criterion(outputs, lbls)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * imgs.size(0)\n            _, preds = torch.max(outputs, 1)\n            train_correct += (preds == lbls).sum().item()\n            train_total += lbls.size(0)\n            pbar_train.set_postfix(loss=loss.item(), acc=train_correct/train_total)\n        \n        avg_train_loss = train_loss / train_total\n        avg_train_acc = train_correct / train_total\n        \n        # Validasi\n        model.eval()\n        val_loss = 0\n        all_labels, all_preds = [], []\n        with torch.no_grad():\n            pbar_val = tqdm(val_loader, desc=f\"Validating Fold {fold+1}\")\n            for imgs, lbls in pbar_val:\n                imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n                outputs = model(imgs)\n                loss = criterion(outputs, lbls)\n                val_loss += loss.item() * imgs.size(0)\n                _, preds = torch.max(outputs, 1)\n                all_labels.extend(lbls.cpu().numpy())\n                all_preds.extend(preds.cpu().numpy())\n        \n        avg_val_loss = val_loss / len(val_dataset)\n        val_acc = accuracy_score(all_labels, all_preds)\n        val_f1 = f1_score(all_labels, all_preds, average='macro')\n        \n        scheduler.step()\n        history['train_loss'].append(avg_train_loss)\n        history['train_acc'].append(avg_train_acc)\n        history['val_loss'].append(avg_val_loss)\n        history['val_acc'].append(val_acc)\n        history['val_f1'].append(val_f1)\n        \n        print(f\"Fold {fold+1} Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Acc: {avg_train_acc:.4f} | Val Loss: {avg_val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            model_path = os.path.join(MODEL_DIR, f\"best_model_fold_{fold}.pth\")\n            torch.save(model.state_dict(), model_path)\n            print(f\"Val ACC meningkat. Menyimpan model ke {model_path}\")\n            \n    fold_histories.append(history)\n\nprint(\"\\nPelatihan K-Fold selesai.\")\n\n# PLOT CURVES\nlast_fold_history = fold_histories[-1]\nplt.figure(figsize=(18, 6))\nplt.subplot(1, 3, 1)\nplt.plot(last_fold_history['train_loss'], label=\"Train Loss\")\nplt.plot(last_fold_history['val_loss'], label=\"Val Loss\")\nplt.title(f\"Loss Curve (Fold {N_FOLDS})\"); plt.legend()\nplt.subplot(1, 3, 2)\nplt.plot(last_fold_history['train_acc'], label=\"Train Accuracy\")\nplt.plot(last_fold_history['val_acc'], label=\"Val Accuracy\")\nplt.title(f\"Accuracy Curve (Fold {N_FOLDS})\"); plt.legend()\nplt.subplot(1, 3, 3)\nplt.plot(last_fold_history['val_f1'], label=\"Val F1-Score (Macro)\")\nplt.title(f\"F1-Score Curve (Fold {N_FOLDS})\"); plt.legend()\nplt.show()\n\n# INFERENCE\ntta_tfms = [\n    val_test_tfms,\n    transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.RandomHorizontalFlip(p=1.0),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.RandomAffine(degrees=10),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n]\n\ndef ensemble_tta_predict(models_list, img_path, tta_transforms, device):\n    img = Image.open(img_path).convert(\"RGB\")\n    all_model_probs = []\n    \n    with torch.no_grad():\n        for model in models_list:\n            model.eval()\n            tta_probs = []\n            for tfm in tta_transforms:\n                x = tfm(img).unsqueeze(0).to(device)\n                out = model(x)\n                tta_probs.append(F.softmax(out, dim=1).cpu().numpy())\n            all_model_probs.append(np.mean(tta_probs, axis=0))\n\n    # Ensemble\n    final_probs = np.mean(all_model_probs, axis=0)\n    return np.argmax(final_probs)\n\nmodels_ensemble = []\nfor fold in range(N_FOLDS):\n    model_path = os.path.join(MODEL_DIR, f\"best_model_fold_{fold}.pth\")\n    model = get_model(BACKBONE, n_classes, pretrained=False).to(DEVICE)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    models_ensemble.append(model)\nprint(f\"\\n{len(models_ensemble)} model dimuat untuk ensemble inference.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prediksi data test\nlabels_pred = []\nfor p in tqdm(test_imgs, desc=\"Predict Test with Ensemble TTA\"):\n    pred = ensemble_tta_predict(models_ensemble, p, tta_tfms, DEVICE)\n    labels_pred.append(pred)\n\nids_test = [os.path.basename(p) for p in test_imgs]\nsubmission = pd.DataFrame({\"Id\": ids_test, \"Predicted\": labels_pred})\nsubmission.to_csv(OUT_FILE, index=False)\nprint(f\"\\n[+] Submission disimpan ke {OUT_FILE}\")\nprint(submission.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}